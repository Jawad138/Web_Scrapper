{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "['/products/light-taupe-2pc-embroidered-lawn-dress', '/products/sage-green-2pc-embroidered-lawn-dress', '/products/green-schiffli-lawn-2pc-dress', '/products/amber-gold-2pc-embroidered-lawn-dress', '/products/cedarwood-2pc-embroidered-lawn-dress', '/products/brown-schiffli-lawn-2pc-dress', '/products/black-3pc-with-chiffon-dupatta', '/products/black-schiffli-lawn-2pc-dress', '/products/lime-2pc-embroidered-lawn-dress', '/products/shocking-pink-schiffli-lawn-2pc-dress', '/products/deep-purple-2pc-dress', '/products/purple-elegance-2pc-embroidered-lawn-dress', '/products/red-violet-schiffli-lawn-2pc-dress', '/products/autumn-blonde-3pc-embroidered-lawn-maxi-dress', '/products/emerald-embroidered-lawn-stitched-dress', '/products/azure-blue-2pc-embroidered-lawn-dress', '/products/terracotta-2pc-embroidered-lawn-dress', '/products/swan-3pc-embroidered-dress', '/products/pansy-embroidered-lawn-stitched-dress', '/products/macadamia-2pc-embroidered-lawn-dress', '/products/black-2-piece', '/products/prelude-2-piece', '/products/rustic-2-piece', '/products/black-suzani', '/products/palm-2-piece', '/products/allure-2pc-dress', '/products/mustard-2-piece', '/products/pine-green-2-piece', '/products/russet-2pc-dress', '/products/rose-wood', '/products/fudge-2pc', '/products/light-taupe-2pc-embroidered-lawn-dress', '/products/pearl-frost-2pc-dress', '/products/cedar-2pc-dress', '/products/raspberry', '/products/moon-light', '/products/evergreen-embroidered-lawn-stitched-dress', '/products/pastel-keppel-embroidered-lawn-stitched-dress', '/products/midnight-mauve-embroidered-lawn-stitched-dress', '/products/spring-olive-embroidered-lawn-stitched-dress', '/products/moss-green-embroidered-lawn-stitched-dress', '/products/picante-embroidered-lawn-stitched-dress', '/products/rain-forest-embroidered-lawn-stitched-dress', '/products/dove-lawn-stitched-3pc-dress', '/products/citrus-lawn-stitched-3pc-dress', '/products/sagebrush-lawn-stitched-3pc-dress', '/products/macadamia-lawn-stitched-3pc-dress', '/products/flora-lawn-stitched-3pc-dress', '/products/peachy-pink-lawn-stitched-3pc-dress', '/products/purple-chiffon-formal-stitched-dress', '/products/pink-chiffon-formal-stitched-dress', '/products/azure-blue-2pc-embroidered-lawn-dress', '/products/gulf-coast-2pc-embroidered-lawn-dress', '/products/tropical-peach-2pc-embroidered-lawn-dress', '/products/purple-elegance-2pc-embroidered-lawn-dress', '/products/green-olive-2pc-embroidered-lawn-dress', '/products/straight-pants', '/products/floral-embroidered-pants', '/products/black-straight-pants', '/products/black-culottes-pants-cambric', '/products/black-side-tulip', '/products/white-embroidered-pants', '/products/off-white-side-emb-pants', '/products/ornaments-tulip', '/products/black-diamond-pants', '/products/white-cigarette-pants', '/products/mens-abstract-printed-cotton-kurta', '/products/mens-texture-printed-cotton-kurta', '/products/mens-white-stitched-cotton-shalwar-kameez', '/products/mens-sea-blue-printed-cotton-kurta', '/products/mens-black-stitched-cotton-shalwar-kameez', '/products/mens-white-cotton-kurta-pajama', '/products/mens-aesh-gray-printed-cotton-kurta', '/products/mens-white-cotton-pajama', '/products/mens-gray-printed-cotton-kurta', '/products/mens-black-cotton-kurta-pajama', '/products/mens-brown-stitched-cotton-shalwar-kameez', '/products/mens-sea-green-printed-cotton-kurta']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the homepage\n",
    "homePage = requests.get(\"https://luxeurs.com/\")\n",
    "\n",
    "# Check if the request was successful\n",
    "if homePage.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(homePage.text, 'html.parser')\n",
    "    \n",
    "    # Find all the <a> tags within elements having the class 'product-card__name'\n",
    "    product_links = soup.find_all('div', class_='product-card__name')\n",
    "    \n",
    "    # Extract the href attributes to get the URLs\n",
    "    urls = [link.a['href'] for link in product_links if link.a]\n",
    "    \n",
    "    # Print or save the URLs\n",
    "    print(len(urls))\n",
    "    print(urls)\n",
    "else:\n",
    "    print(\"Failed to retrieve the homepage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element text: Light Taupe 2PC Embroidered Lawn Dress\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://luxeurs.com/products/light-taupe-2pc-embroidered-lawn-dress\"\n",
    "\n",
    "# Send a GET request to the website\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the element with the specified class\n",
    "element = soup.find('h1', class_='product-single__title')\n",
    "\n",
    "# Get the text from the element\n",
    "if element:\n",
    "    text = element.get_text(strip=True)\n",
    "    print(f\"Element text: {text}\")\n",
    "else:\n",
    "    print(\"Element not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: https://luxeurs.com/cdn/shop/files/36_6fe447d1-12dc-4731-bf50-29648d5134a5_1080x1080.jpg?v=1722186484\n"
     ]
    }
   ],
   "source": [
    "div = soup.find('div', class_='product-media__wrapper')\n",
    "\n",
    "# Extract all image URLs within the div\n",
    "image_urls = []\n",
    "if div:\n",
    "    images = div.find_all('img')\n",
    "    for img in images:\n",
    "        # Construct the full image URL\n",
    "        img_url = img['src']\n",
    "        full_img_url = \"https:\" + img_url\n",
    "        image_urls.append(full_img_url)\n",
    "\n",
    "# Print all the extracted image URLs\n",
    "for idx, url in enumerate(image_urls, start=1):\n",
    "    print(f\"Image {idx}: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.24.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in d:\\ecodecamp\\task 5\\web_scrapper\\venv\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Using cached trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in d:\\ecodecamp\\task 5\\web_scrapper\\venv\\lib\\site-packages (from selenium) (2024.7.4)\n",
      "Collecting typing_extensions~=4.9 (from selenium)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in d:\\ecodecamp\\task 5\\web_scrapper\\venv\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in d:\\ecodecamp\\task 5\\web_scrapper\\venv\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in d:\\ecodecamp\\task 5\\web_scrapper\\venv\\lib\\site-packages (from trio~=0.17->selenium) (3.8)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio~=0.17->selenium)\n",
      "  Using cached cffi-1.17.0-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ecodecamp\\task 5\\web_scrapper\\venv\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.17->selenium)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.24.0-py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.6 MB 5.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.1/9.6 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.1/9.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.5/9.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.8/9.6 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.1/9.6 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.6 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Using cached trio-0.26.2-py3-none-any.whl (475 kB)\n",
      "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached cffi-1.17.0-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sortedcontainers, websocket-client, typing_extensions, sniffio, python-dotenv, pysocks, pycparser, h11, attrs, wsproto, webdriver-manager, outcome, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-24.2.0 cffi-1.17.0 h11-0.14.0 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 python-dotenv-1.0.1 selenium-4.24.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.26.2 trio-websocket-0.11.1 typing_extensions-4.12.2 webdriver-manager-4.0.2 websocket-client-1.8.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price element not found or not visible on the page.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# URL of the product page\n",
    "url = \"https://luxeurs.com/products/deep-purple-2pc-dress\"\n",
    "\n",
    "# Open the URL\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the price element to be visible and then find it\n",
    "try:\n",
    "    price_tag = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.CLASS_NAME, \"money\"))\n",
    "    )\n",
    "    # Extract the price text\n",
    "    price = price_tag.text\n",
    "    print(f\"Price: {price}\")\n",
    "except:\n",
    "    print(\"Price element not found or not visible on the page.\")\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 404 Client Error: Not Found for url: https://luxeurs.com/your-product-page-url\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of a single product page for testing\n",
    "product_url = \"https://luxeurs.com/your-product-page-url\"  # Replace with an actual product URL\n",
    "\n",
    "try:\n",
    "    # Send a GET request to the product page\n",
    "    product_page = requests.get(product_url)\n",
    "    product_page.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)\n",
    "\n",
    "    # Parse the product page content\n",
    "    product_soup = BeautifulSoup(product_page.text, 'html.parser')\n",
    "    \n",
    "    # Extract the sale price if available\n",
    "    sale_price_tag = product_soup.find('span', class_='js-product-price')\n",
    "    if sale_price_tag:\n",
    "        price = sale_price_tag.get_text(strip=True)\n",
    "    else:\n",
    "        # Fallback to regular price if sale price is not available\n",
    "        price_tag = product_soup.find('span', class_='money')\n",
    "        price = price_tag.get_text(strip=True) if price_tag else \"Price not available\"\n",
    "    \n",
    "    print(f\"Price: {price}\")\n",
    "\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
